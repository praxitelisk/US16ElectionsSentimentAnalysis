{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on tweets for US 16 Election Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will try to analyze tweets before US 16 Elections, on May 25 until May 27. Tweets was initially fetched with a python tweepy streamer and stored at a mongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### parsing the mongoDB databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "client = MongoClient(\"127.0.0.1:27017\")\n",
    "\n",
    "#name of the db\n",
    "db = client[\"dbTweetsForAnalysis\"]\n",
    "\n",
    "#name of the collection\n",
    "coll = db['rawTweetsForAnalysis']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize all text and save all words in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#makehillarydebateagain', '@hillaryclinton', 'promised,', 'debate!', 'flakes', 'debate,', 'whats', 'next?', '#justsaying', 'whaaa!!!!!!', '@realdonaldtrump', 'choose', 'color!', '@keitholbermann:', 'calling', 'death', 'vince', 'foster', 'fishy,', 'thus', 'question:', 'account', 'whereabouts', '@marv_vien:', 'trump', 'nra', 'got', 'nothing', '@sybrinafulton,', 'mothers', 'movement', '#stopgunviolence', '@davidaxelrod', '@sensanders', 'numbers', 'decline', '#as', 'usual', '#bad', 'candidate', '@realdonaldtrump:', 'thank', 'america!', '#trump2016', '@salon', 'vote', 'clintonsbill', 'presidenthilary', 'maidand', 'cleaned', 'americano', 'repeatsvote', '@foxnews:', 'tough', 'vigilant', 'smart,', 'going', 'big', 'trouble', '@realthebernison:', 'berniesanders:', 'disappointed', 'surprised', 'secretary', 'clintons', 'unwillingness', 'debate', 'large', 'ht', 'saw', 'day1', 'anointed', 'god', '4this', 'point', 'time', 'help', '2return', 'olandogod', '100%', '#potustrump', '2016']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "#just fetch all json files from mongoDB collection\n",
    "cursor = coll.find()\n",
    "\n",
    "wordList = []\n",
    "dictWords = {}\n",
    "tokenizer = RegexpTokenizer(pattern=\"[^ ]+\")\n",
    "english_stops = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "for document in cursor[:10]:\n",
    "    if \"lang\" in document and \"text\" in document and document[\"lang\"] == \"en\":\n",
    "        \n",
    "        text =  document[\"text\"].encode(\"utf-8\")\n",
    "        \n",
    "        #cleaning the text\n",
    "        text = str(text)\n",
    "        text = text[2:]\n",
    "        \n",
    "        text = re.sub(\"http[s]?:*/*/*.*\", \"\", text)\n",
    "        text = re.sub(\"RT \", \"\", text)\n",
    "        text = re.sub(\"[\\\\\\]x.{2}\", \"\", text)\n",
    "        text = re.sub(\"[\\\\\\]\\'\", \"\\'\", text)\n",
    "        text = re.sub(\"\\\"\", \"\", text)\n",
    "        text = re.sub(\"\\'\", \"\", text)\n",
    "        text = re.sub(\"[\\\\\\]n\", \"\", text)\n",
    "        text = re.sub(\"&.+;\", \"\", text)\n",
    "        text = re.sub(\"[a-zA-z]/\", \"\", text)\n",
    "        text = re.sub(\"\\.\", \"\", text)\n",
    "        text = re.sub(\"~\", \"\", text)\n",
    "        text = str.lower(text)\n",
    "        #print(text,\"\\n\")\n",
    "        \n",
    "        words =  tokenizer.tokenize(text)\n",
    "        for word in words:\n",
    "            if word not in english_stops:\n",
    "                if word not in dictWords:\n",
    "                    dictWords[word] = 1\n",
    "                    wordList.append(word)\n",
    "                else:\n",
    "                    dictWords[word] += 1\n",
    "\n",
    "\n",
    "        \n",
    "               \n",
    "\n",
    "#sort the dict by key\n",
    "#dictWords = collections.OrderedDict(sorted(dictWords.items()))\n",
    "\n",
    "#for item, value in dictWords.items():\n",
    "#    if value > 10:\n",
    "#        print(item,\":\", value,\"\\n\")\n",
    "\n",
    "print(wordList)\n",
    "        \n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing repeating words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperating the generic dictWords to smaller dictionaries containg mentions, hashtags and clear tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#makehillarydebateagain', '@hillaryclinton', 'promised,', 'debate!', 'flak', 'debate,', 'what', 'next?', '#justsaying', 'whaaa!!!!!!', '@realdonaldtrump', 'choos', 'color!', '@keitholbermann:', 'cal', 'dea', 'vint', 'fost', 'fishy,', 'thu', 'question:', 'account', 'whereabout', '@marv_vien:', 'trump', 'nra', 'got', 'noth', '@sybrinafulton,', 'moth', 'mov', '#stopgunviolence', '@davidaxelrod', '@sensanders', 'numb', 'declin', '#as', 'us', '#bad', 'candid', '@realdonaldtrump:', 'thank', 'america!', '#trump2016', '@salon', 'vot', 'clintonsbil', 'presidenthil', 'maidand', 'cle', 'americano', 'repeatsvot', '@foxnews:', 'tough', 'vigil', 'smart,', 'going', 'big', 'troubl', '@realthebernison:', 'berniesanders:', 'disappoint', 'surpr', 'secret', 'clinton', 'unwil', 'deb', 'larg', 'ht', 'saw', 'day1', 'anoint', 'god', '4this', 'point', 'tim', 'help', '2return', 'olandogod', '100%', '#potustrump', '2016']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "stemmedWordList = []\n",
    "\n",
    "for word in wordList:\n",
    "    \n",
    "    stemmedWordList.append(stemmer.stem(word))\n",
    "    \n",
    "print (stemmedWordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#makehillarydebateagain', '@hillaryclinton', 'promised,', 'debate!', 'flake', 'debate,', 'whats', 'next?', '#justsaying', 'whaaa!!!!!!', '@realdonaldtrump', 'choose', 'color!', '@keitholbermann:', 'calling', 'death', 'vince', 'foster', 'fishy,', 'thus', 'question:', 'account', 'whereabouts', '@marv_vien:', 'trump', 'nra', 'got', 'nothing', '@sybrinafulton,', 'mother', 'movement', '#stopgunviolence', '@davidaxelrod', '@sensanders', 'number', 'decline', '#as', 'usual', '#bad', 'candidate', '@realdonaldtrump:', 'thank', 'america!', '#trump2016', '@salon', 'vote', 'clintonsbill', 'presidenthilary', 'maidand', 'cleaned', 'americano', 'repeatsvote', '@foxnews:', 'tough', 'vigilant', 'smart,', 'going', 'big', 'trouble', '@realthebernison:', 'berniesanders:', 'disappointed', 'surprised', 'secretary', 'clinton', 'unwillingness', 'debate', 'large', 'ht', 'saw', 'day1', 'anointed', 'god', '4this', 'point', 'time', 'help', '2return', 'olandogod', '100%', '#potustrump', '2016']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "LemmaWordList = []\n",
    "\n",
    "for word in wordList:\n",
    "    \n",
    "    LemmaWordList.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "print (LemmaWordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
